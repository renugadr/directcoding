import streamlit as st
from PIL import Image
import numpy as np
import cv2

# Set up Streamlit app
st.set_page_config(page_title="Vision Wizard", page_icon="ðŸ§™â€â™‚ï¸", layout="wide")

st.title("Vision Wizard ðŸ§™â€â™‚ï¸âœ¨: Simplifying Computer Vision Tasks")

page = st.sidebar.radio("*ðŸŒ Select a Feature*", ["Home Page ðŸ ", "Image Resizing ðŸ“ðŸ”„", "Image Grayscale Conversion ðŸŒ‘ðŸ”„", "Edge Detection âœ‚ï¸ðŸ”", "Image Rotation ðŸ”„â†ªï¸", "Image Cropping âœ‚ï¸ðŸ–¼ï¸", "Image Flipping â†”ï¸ðŸ”„", "Color Space Conversion ðŸŒˆðŸ”„", "Image Brightness/Contrast Adjustment â˜€ï¸ðŸŒ‘", "Image Blurring ðŸŒ«ï¸ðŸ”„", "Histogram Equalization ðŸ“Šâœ¨", "Face Detection ðŸ˜ŠðŸ”", "Image Segmentation ðŸ§©ðŸ“¦", "Quick Links ðŸ”—"])

def clear_session_state():
    st.session_state.pop("input_method", None)
    st.session_state.pop("uploaded_file", None)
    st.session_state.pop("capture_image", None)
    st.session_state.pop("image", None)
    
def get_image_input():
    # Check if image is already in session state
    if 'image' not in st.session_state:
        st.session_state.image = None

    # Function to check image complexity
    def is_image_complex(image):
        img_array = np.array(image)
        return img_array.shape[0] * img_array.shape[1] > 10000 * 10000  # Example threshold

    # Function to check image size
    def is_file_size_ok(file):
        file.seek(0, 2)  # Move to end of file
        file_size = file.tell()
        file.seek(0, 0)  # Move back to start of file
        return file_size <= 10 * 1024 * 1024  # 10 MB limit

    # Choose input method
    input_method = st.radio("*Select Image Input Method:* ðŸ“¸",
                            ("ðŸ“ Upload Image", "ðŸ“· Capture Image", "ðŸ–¼ï¸ Use Example Image"))

    if input_method == "ðŸ“ Upload Image":
        uploaded_file = st.file_uploader("Choose an image ðŸ“‚", type=["jpg", "jpeg", "png"])
        if st.button("ðŸ“ Submit Image"):
            if uploaded_file is not None:
                if not is_file_size_ok(uploaded_file):
                    st.error("âŒ Uploaded image is too large. Please upload an image smaller than 10MB.")
                    return None
                try:
                    image = Image.open(uploaded_file)
                    if is_image_complex(image):
                        st.error("âŒ Uploaded image is too complex to process. Please upload a simpler image.")
                        return None
                    st.session_state.image = image
                except Exception as e:
                    st.error(f"âŒ An error occurred: {str(e)}")
                    return None
            else:
                st.error("âŒ Error: Please upload an image.")

    elif input_method == "ðŸ–¼ï¸ Use Example Image":
        example_image_path = "example.jpg"  # Ensure this file is in the same directory
        try:
            image = Image.open(example_image_path)
            st.session_state.image = image
        except Exception as e:
            st.error(f"âŒ An error occurred: {str(e)}")
            return None

    elif input_method == "ðŸ“· Capture Image":
        capture_image = st.camera_input("Capture an image")
        if st.button("ðŸ“· Submit Image"):
            if capture_image is not None:
                try:
                    image = Image.open(capture_image)
                    if is_image_complex(image):
                        st.error("âŒ Captured image is too complex to process. Please capture a simpler image.")
                        return None
                    st.session_state.image = image
                except Exception as e:
                    st.error(f"âŒ An error occurred: {str(e)}")
                    return None
            else:
                st.error("âŒ Error: Please take a photo.")

    return st.session_state.image

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def detect_faces(image):
    # Convert PIL image to grayscale OpenCV image
    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    return faces
    
# List of pages to exclude the common input section
exclude_input_pages = ["Home Page ðŸ ", "Quick Links ðŸ”—"]

if page not in exclude_input_pages:
    # Common input section for pages not in the exclude list
    image = get_image_input()

    # Add a button to clear the session state
    if st.button("ðŸ—‘ï¸ Clear Input"):
        clear_session_state()
      
    st.info("âš ï¸ Click 'ðŸ—‘ï¸ Clear Input' to reset the image input fields. This will clear all entered data and allow you to start fresh.")

# Page 1
if page == "Home Page ðŸ ":
    st.subheader("Discover the power of computer vision with easy-to-use tools and techniques in Vision Wizard.")
    st.markdown("_____")
    st.header("Explore the following features:")
    st.markdown("""
    ðŸ”¸ *Image Resizing ðŸ“ðŸ”„*: Resize your images to different dimensions.
    
    ðŸ”¸ *Image Grayscale Conversion ðŸŒ‘ðŸ”„*: Convert images to grayscale.
    
    ðŸ”¸ *Edge Detection âœ‚ï¸ðŸ”*: Detect edges in images.
    
    ðŸ”¸ *Image Rotation ðŸ”„â†ªï¸*: Rotate images to a desired angle.
    
    ðŸ”¸ *Image Cropping âœ‚ï¸ðŸ–¼ï¸*: Crop images to focus on specific areas.
    
    ðŸ”¸ *Image Flipping â†”ï¸ðŸ”„*: Flip images horizontally or vertically.
    
    ðŸ”¸ *Color Space Conversion ðŸŒˆðŸ”„*: Convert images between different color spaces.
    
    ðŸ”¸ *Image Brightness/Contrast Adjustment â˜€ï¸ðŸŒ‘*: Adjust the brightness and contrast of images.
    
    ðŸ”¸ *Image Blurring ðŸŒ«ï¸ðŸ”„*: Apply blurring effects to images.
    
    ðŸ”¸ *Histogram Equalization ðŸ“Šâœ¨*: Enhance the contrast of images using histogram equalization.
    
    ðŸ”¸ *Face Detection ðŸ˜ŠðŸ”*: Detect faces in images.
    
    ðŸ”¸ *Image Segmentation ðŸ§©ðŸ“¦*: Segment images into distinct regions.
    """)

# Page 2
elif page == "Image Resizing ðŸ“ðŸ”„":
    st.header("ðŸ“ðŸ”„ Image Resizing Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        width, height = image.size
        st.subheader(f"*Original Image Dimensions:* {width} x {height}")
        new_width = st.number_input("New Width", value=width, min_value=1, max_value=6000)
        new_height = st.number_input("New Height", value=height, min_value=1, max_value=6000)
        resized_image = image.resize((new_width, new_height))
        if st.button("ðŸ”„ Resize Image"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader('Resized Image')
            st.image(resized_image, caption='Resized Image', use_container_width=True)
            img_array = np.array(resized_image)
            resized_img = Image.fromarray(img_array)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 3
elif page == "Image Grayscale Conversion ðŸŒ‘ðŸ”„":
    st.header("ðŸŒ‘ðŸ”„ Image Grayscale Conversion Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("ðŸŒ‘ Perform Grayscale Conversion"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("â¬› Grayscale Image") 
            img_array = np.array(image)
            gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
            st.image(gray_img, caption='Grayscale Image', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")
        
# Page 4
elif page == "Edge Detection âœ‚ï¸ðŸ”":
    st.header("âœ‚ï¸ðŸ” Edge Detection Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        method = st.radio("âœ‚ï¸ *Select Edge Detection Method*", ["Canny", "Sobel", "Laplacian"])
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        if method == "Canny":
            threshold1 = st.slider("Threshold 1", 0, 255, 100)
            threshold2 = st.slider("Threshold 2", 0, 255, 200)
            edges = cv2.Canny(opencv_image, threshold1, threshold2)
        elif method == "Sobel":
            dx = st.slider("dx", 0, 1, 1)
            dy = st.slider("dy", 0, 1, 1)
            ksize = st.slider("Kernel Size (must be odd)", 1, 31, 3, step=2)
            edges = cv2.Sobel(opencv_image, cv2.CV_64F, dx, dy, ksize=ksize)
            edges = cv2.convertScaleAbs(edges)  # Convert the result to uint8
        elif method == "Laplacian":
            ksize = st.slider("Kernel Size (must be odd)", 1, 31, 3, step=2)
            edges = cv2.Laplacian(opencv_image, cv2.CV_64F, ksize=ksize)
            edges = cv2.convertScaleAbs(edges)  # Convert the result to uint8
        if st.button("ðŸ” Perform Edge Detection"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ” Image with Detected Edges") 
            st.image(edges, caption=f'Edges Detected using {method}', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 5
elif page == "Image Rotation ðŸ”„â†ªï¸":
    st.header("ðŸ”„â†ªï¸ Image Rotation Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        angle = st.slider("Rotate Angle", min_value=0, max_value=360, value=0)
        if st.button("â†ªï¸ Rotate Image"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ”„ Rotated Image") 
            rotated_image = image.rotate(angle)
            st.image(rotated_image, caption=f'Image Rotated by {angle} degrees', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 6
elif page == "Image Cropping âœ‚ï¸ðŸ–¼ï¸":
    st.header("âœ‚ï¸ðŸ–¼ï¸ Image Cropping Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        width, height = image.size
        x = st.number_input("X Coordinate", value=0, min_value=0, max_value=width-1, step=1)
        y = st.number_input("Y Coordinate", value=0, min_value=0, max_value=height-1, step=1)
        max_crop_width = width - x
        max_crop_height = height - y
        new_width = st.number_input("Crop Width", value=max_crop_width, min_value=1, max_value=max_crop_width, step=1)
        new_height = st.number_input("Crop Height", value=max_crop_height, min_value=1, max_value=max_crop_height, step=1)
        if st.button("âœ‚ï¸ Crop Image"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("âœ‚ï¸ Cropped Image")
            cropped_image = image.crop((x, y, x + new_width, y + new_height))
            st.image(cropped_image, caption='Cropped Image', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 7
elif page == "Image Flipping â†”ï¸ðŸ”„":
    st.header("â†”ï¸ðŸ”„ Image Flipping Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        flip_option = st.radio("ðŸ”„ *Flip Option*", ["Horizontal Flip", "Vertical Flip", "Diagonal Flip"])
        img_array = np.array(image)
        if flip_option == "Horizontal Flip":
            flipped_image = cv2.flip(img_array, 1)
        elif flip_option == "Diagonal Flip":
            flipped_image = image.transpose(Image.ROTATE_90).transpose(Image.FLIP_LEFT_RIGHT)
        else:
            flipped_image = cv2.flip(img_array, 0)
        if st.button("â†”ï¸ Flip Image"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("â†”ï¸ Flipped Image")
            st.image(flipped_image, caption=f'Image with {flip_option}', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 8
elif page == "Color Space Conversion ðŸŒˆðŸ”„":
    st.header("ðŸŒˆðŸ”„ Color Space Conversion Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        color_space = st.radio("ðŸ”´ðŸŸ¢ðŸ”µ *Color Space*", ["RGB", "HSV", "LAB", "HLS", "YCbCr"])
        img_array = np.array(image)
        if color_space == "HSV":
            converted_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)
        elif color_space == "LAB":
            converted_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2LAB)
        elif color_space == "YCbCr":
            converted_img = image.convert("YCbCr")
        elif color_space == "HLS":
            converted_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2HLS)
            converted_img = Image.fromarray(converted_image)
        else:
            converted_img = img_array
        if st.button("ðŸ“Ÿ Convert Color Space"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸŒŸ Converted Image")
            st.image(converted_img, caption=f'Image in {color_space} Color Space', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 9
elif page == "Image Brightness/Contrast Adjustment â˜€ï¸ðŸŒ‘":
    st.header("â˜€ï¸ðŸŒ‘ Image Brightness/Contrast Adjustment Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        brightness = st.slider("Adjust Brightness", -100, 100, 0)
        contrast = st.slider("Adjust Contrast", -100, 100, 0)
        if st.button("â˜€ï¸ Adjust Brightness/Contrast"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ“· Adjusted Image")
            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            adjusted = cv2.convertScaleAbs(opencv_image, alpha=1 + contrast / 100, beta=brightness)
            st.image(adjusted, caption='Brightness/Contrast Adjusted Image', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 10
elif page == "Image Blurring ðŸŒ«ï¸ðŸ”„":
    st.header("ðŸŒ«ï¸ðŸ”„ Image Blurring Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        blur_type = st.radio("ðŸŒ«ï¸ *Choose Blurring Effect*", ["Gaussian Blur", "Median Blur", "Bilateral Filter"])
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        if blur_type == "Gaussian Blur":
            ksize = st.slider("Kernel Size", min_value=1, max_value=50, value=5, step=2)
            blurred_image = cv2.GaussianBlur(opencv_image, (ksize, ksize), 0)
        elif blur_type == "Median Blur":
            ksize = st.slider("Kernel Size", min_value=1, max_value=50, value=5, step=2)
            if ksize % 2 == 0:
                ksize += 1  # Kernel size must be odd for median blur
            blurred_image = cv2.medianBlur(opencv_image, ksize)
        elif blur_type == "Bilateral Filter":
            d = st.slider("Diameter", min_value=1, max_value=50, value=9)
            sigmaColor = st.slider("Sigma Color", min_value=1, max_value=100, value=75)
            sigmaSpace = st.slider("Sigma Space", min_value=1, max_value=100, value=75)
            blurred_image = cv2.bilateralFilter(opencv_image, d, sigmaColor, sigmaSpace)
        if st.button("ðŸ“Ÿ Blur Image"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ‘“ Blurred Image")
            blurred_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)
            blurred_image = Image.fromarray(blurred_image)
            st.image(blurred_image, caption=f'{blur_type} Applied', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 11
elif page == "Histogram Equalization ðŸ“Šâœ¨":
    st.header("ðŸ“Šâœ¨ Histogram Equalization Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("ðŸ“Š Perform Histogram Equalization"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("âœ¨ Histogram Equalized Image")
            img_array = np.array(image)
            gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
            equalized_img = cv2.equalizeHist(gray_img)
            st.image(equalized_img, caption='Histogram Equalized Image', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 12
elif page == "Face Detection ðŸ˜ŠðŸ”":
    st.header("ðŸ˜ŠðŸ” Face Detection Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("ðŸ˜Š Detect Faces"):
            st.subheader("ðŸ–¼ï¸ Original Image") 
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ” Detected Faces")
            faces = detect_faces(image)
            if len(faces) == 0:
                st.error("âš ï¸ No faces detected in the image. Please try another image.")
            else:
                st.success(f"ðŸ˜Š Detected {len(faces)} face(s).")
                # Draw rectangles around the faces
                draw_image = np.array(image.copy())
                for (x, y, w, h) in faces:
                    cv2.rectangle(draw_image, (x, y), (x+w, y+h), (255, 0, 0), 2)
                st.image(draw_image, caption='Detected Faces', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

# Page 13
elif page == "Image Segmentation ðŸ§©ðŸ“¦":
    st.header("ðŸ§©ðŸ“¦ Image Segmentation Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        # Convert session state image to OpenCV format
        opencv_image = cv2.cvtColor(np.array(st.session_state.image), cv2.COLOR_RGB2BGR)
        # Sliders for user-adjustable parameters
        iterations = st.slider("Number of Iterations", min_value=1, max_value=10, value=5, step=1)
        rect_x = st.slider("Rectangle X-coordinate", min_value=0, max_value=opencv_image.shape[1] // 2, value=50)
        rect_y = st.slider("Rectangle Y-coordinate", min_value=0, max_value=opencv_image.shape[0] // 2, value=50)
        rect_width = st.slider("Rectangle Width", min_value=50, max_value=opencv_image.shape[1], value=opencv_image.shape[1] - 50)
        rect_height = st.slider("Rectangle Height", min_value=50, max_value=opencv_image.shape[0], value=opencv_image.shape[0] - 50)
        if st.button("ðŸ§© Segment Image"):
            st.subheader("ðŸ–¼ï¸ Original Image")
            st.image(image, caption='Original Image', use_container_width=True)
            st.subheader("ðŸ“¦ Segmented Image")
            # Create the mask and models
            mask = np.zeros(opencv_image.shape[:2], np.uint8)
            bgd_model = np.zeros((1, 65), np.float64)
            fgd_model = np.zeros((1, 65), np.float64)
            # Define the rectangle
            rect = (rect_x, rect_y, rect_width, rect_height)
            # Perform GrabCut
            cv2.grabCut(opencv_image, mask, rect, bgd_model, fgd_model, iterations, cv2.GC_INIT_WITH_RECT)
            # Apply the mask to segment the image
            mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
            segmented_image = opencv_image * mask2[:, :, np.newaxis]
            # Display the segmented image
            st.image(segmented_image, caption='Segmented Image', use_container_width=True)
    else:
        st.info("âš ï¸ Please upload or capture an image, or use an example image.")

elif page == "Quick Links ðŸ”—":
    st.header("ðŸ”— Quick Links")
    st.write("Click on any link below to navigate to the respective application:")

    links = {
        "ðŸ¤– Model Craft": "https://modelcraft-uihxqxgjthmusarv6kscuz.streamlit.app/",
        "âœï¸ TextTrac": "https://texttrac-mmmj5kiucvh9muj66gekp4.streamlit.app/",
        "ðŸ“‚ Data Weaver": "https://aybzbegfeczo4yfievejqk.streamlit.app/",
        "ðŸ› ï¸ SkillSync": "https://skillsync-b8xdmwmdezbzf66qpbuj5j.streamlit.app/",
        "ðŸ’° TradeLens": "https://glseycvc2rbucwhk3esh85.streamlit.app/"
    }
    
    for name, url in links.items():
        st.link_button(name, url, use_container_width=True)
